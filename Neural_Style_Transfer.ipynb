{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import imageio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output image directory\n",
    "OUTPUT_DIR = '/Users/til018/Desktop/style/output/'\n",
    "# Style image\n",
    "STYLE_IMAGE = '/Users/til018/Desktop/style/style_image1.jpg'\n",
    "#Resize it down to match the content image's size\n",
    "img = Image.open(STYLE_IMAGE)\n",
    "img = img.resize((458,326), Image.ANTIALIAS)\n",
    "img.save('/Users/til018/Desktop/style/style_image3.jpg')\n",
    "STYLE_IMAGE = '/Users/til018/Desktop/style/style_image3.jpg'\n",
    "\n",
    "# Content image\n",
    "CONTENT_IMAGE = '/Users/til018/Desktop/style/content_image1.jpg'\n",
    "\n",
    "IMAGE_WIDTH = 458\n",
    "IMAGE_HEIGHT = 326\n",
    "COLOR_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Noise ratio\n",
    "NOISE_RATIO = 0.5\n",
    "# Constant for putting content content loss\n",
    "CONTENT_LOSS_RATIO = 5\n",
    "# Constant for putting style loss\n",
    "STYLE_LOSS_RATIO = 100\n",
    "#VGG19 model\n",
    "VGG_MODEL = 'imagenet-vgg-verydeep-19.mat'\n",
    "\n",
    "# VGG19 mean value to train\n",
    "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vgg_model(path):\n",
    "    #Load VGG19 model\n",
    "    vgg19 = scipy.io.loadmat('/Users/til018/Desktop/style/imagenet-vgg-verydeep-19.mat')\n",
    "\n",
    "    vgg_layers = vgg19['layers']\n",
    "    \n",
    "    #Return weight and bias for the given layer\n",
    "    def _weights(layer, expected_layer_name):\n",
    "        W = vgg_layers[0][layer][0][0][0][0][0]\n",
    "        b = vgg_layers[0][layer][0][0][0][0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][-2]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b\n",
    "    \n",
    "    #Build relu neurons\n",
    "    def _relu(conv2d_layer):\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    #Build convolutional layer\n",
    "    def _conv2d(prev_layer_name, layer, layer_name):\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(\n",
    "            prev_layer_name, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "    \n",
    "    #Build convolutional layer + relu\n",
    "    def _conv2d_relu(prev_layer_name, layer, layer_name):\n",
    "        return _relu(_conv2d(prev_layer_name, layer, layer_name))\n",
    "\n",
    "    #Build average pool layer\n",
    "    def _avgpool(prev_layer_name):\n",
    "        return tf.nn.avg_pool(prev_layer_name, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Constructs the graph model.\n",
    "    layer = {}\n",
    "    layer['input']   = tf.Variable(np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)), dtype = 'float32')\n",
    "    layer['conv1_1']  = _conv2d_relu(layer['input'], 0, 'conv1_1')\n",
    "    layer['conv1_2']  = _conv2d_relu(layer['conv1_1'], 2, 'conv1_2')\n",
    "    layer['avgpool1'] = _avgpool(layer['conv1_2'])\n",
    "    layer['conv2_1']  = _conv2d_relu(layer['avgpool1'], 5, 'conv2_1')\n",
    "    layer['conv2_2']  = _conv2d_relu(layer['conv2_1'], 7, 'conv2_2')\n",
    "    layer['avgpool2'] = _avgpool(layer['conv2_2'])\n",
    "    layer['conv3_1']  = _conv2d_relu(layer['avgpool2'], 10, 'conv3_1')\n",
    "    layer['conv3_2']  = _conv2d_relu(layer['conv3_1'], 12, 'conv3_2')\n",
    "    layer['conv3_3']  = _conv2d_relu(layer['conv3_2'], 14, 'conv3_3')\n",
    "    layer['conv3_4']  = _conv2d_relu(layer['conv3_3'], 16, 'conv3_4')\n",
    "    layer['avgpool3'] = _avgpool(layer['conv3_4'])\n",
    "    layer['conv4_1']  = _conv2d_relu(layer['avgpool3'], 19, 'conv4_1')\n",
    "    layer['conv4_2']  = _conv2d_relu(layer['conv4_1'], 21, 'conv4_2')\n",
    "    layer['conv4_3']  = _conv2d_relu(layer['conv4_2'], 23, 'conv4_3')\n",
    "    layer['conv4_4']  = _conv2d_relu(layer['conv4_3'], 25, 'conv4_4')\n",
    "    layer['avgpool4'] = _avgpool(layer['conv4_4'])\n",
    "    layer['conv5_1']  = _conv2d_relu(layer['avgpool4'], 28, 'conv5_1')\n",
    "    layer['conv5_2']  = _conv2d_relu(layer['conv5_1'], 30, 'conv5_2')\n",
    "    layer['conv5_3']  = _conv2d_relu(layer['conv5_2'], 32, 'conv5_3')\n",
    "    layer['conv5_4']  = _conv2d_relu(layer['conv5_3'], 34, 'conv5_4')\n",
    "    layer['avgpool5'] = _avgpool(layer['conv5_4'])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute content loss\n",
    "def content_loss_func(sess, model):\n",
    "    def _content_loss(p, x):\n",
    "        #Number of filters\n",
    "        filter_num = p.shape[3]\n",
    "        #Feature map size\n",
    "        feature_map = p.shape[1] * p.shape[2]\n",
    "        #The original paper uses the following function\n",
    "        #   0.5 * tf.reduce_sum(tf.pow(x - p, 2)) \n",
    "        #But according to http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n",
    "        # \"This form is very slow in \"painting\" and thus could be missing\n",
    "        # out some constants \"\n",
    "        #So the following function is implemented\n",
    "        return (1 / (4 * filter_num * feature_map)) * tf.reduce_sum(tf.pow(x - p, 2))\n",
    "    return _content_loss(sess.run(model['conv4_2']), model['conv4_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Style layers\n",
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.5),\n",
    "    ('conv2_1', 1.0),\n",
    "    ('conv3_1', 1.5),\n",
    "    ('conv4_1', 3.0),\n",
    "    ('conv5_1', 4.0),\n",
    "]\n",
    "\n",
    "#Style loss\n",
    "def style_loss_func(sess, model):\n",
    "    \n",
    "    #Construct gram matrix\n",
    "    def _gram_matrix(F, filter_num, feature_map):      \n",
    "        gm = tf.reshape(F, (feature_map, filter_num))\n",
    "        return tf.matmul(tf.transpose(gm), gm)\n",
    "\n",
    "    def _style_loss(a, x):\n",
    "        # N is the number of filters (at layer l).\n",
    "        filter_num = a.shape[3]\n",
    "        # M is the height times the width of the feature map (at layer l).\n",
    "        feature_map = a.shape[1] * a.shape[2]\n",
    "        # A is the style representation of the original image (at layer l).\n",
    "        style_original = _gram_matrix(a, filter_num, feature_map)\n",
    "        # G is the style representation of the generated image (at layer l).\n",
    "        style_new = _gram_matrix(x, filter_num, feature_map)\n",
    "        result = (1 / (4 * filter_num**2 * feature_map**2)) * tf.reduce_sum(tf.pow(style_new - style_original, 2))\n",
    "        return result\n",
    "\n",
    "    E = [_style_loss(sess.run(model[layer_name]), model[layer_name]) for layer_name, _ in STYLE_LAYERS]\n",
    "    W = [w for _, w in STYLE_LAYERS]\n",
    "    loss = sum([W[l] * E[l] for l in range(len(STYLE_LAYERS))])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate new image with noise\n",
    "def generate_noise_image(content_image, noise_ratio = NOISE_RATIO):\n",
    "    #White noise picture\n",
    "    noise_image = np.random.uniform(-20, 20, (1, 326, 458, COLOR_CHANNELS)).astype('float32')\n",
    "    #White noise picture with content image weight\n",
    "    new_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    return new_image\n",
    "\n",
    "#Helper function for loading image\n",
    "def load_image(path):\n",
    "    image = imageio.imread(path)\n",
    "    image = np.reshape(image, ((1,) + image.shape))\n",
    "    #Subtract VGG mean from image picture\n",
    "    image = image - MEAN_VALUES\n",
    "    return image\n",
    "\n",
    "#Helper function for writing out image\n",
    "def save_image(path, image):\n",
    "    #Add back vgg mean to output picture\n",
    "    image = image + MEAN_VALUES\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    imageio.imwrite(path,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_vgg_model(VGG_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = load_image(CONTENT_IMAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image = load_image(STYLE_IMAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image = generate_noise_image(content_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute content loss\n",
    "sess.run(model['input'].assign(content_image))\n",
    "loss_content = content_loss_func(sess, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute style loss\n",
    "sess.run(model['input'].assign(style_image))\n",
    "loss_style = style_loss_func(sess, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute totale loss\n",
    "loss_total = CONTENT_LOSS_RATIO * loss_content + STYLE_LOSS_RATIO * loss_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "train_step = optimizer.minimize(loss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -3.75210838e+01,  -3.42395363e+01,  -1.63943920e+01],\n",
       "         [ -4.38560028e+01,  -3.14248943e+01,  -1.40299482e+01],\n",
       "         [ -4.76287041e+01,  -2.27805214e+01,  -1.29070234e+01],\n",
       "         ..., \n",
       "         [ -2.38486366e+01,   6.06310129e+00,   1.08051996e+01],\n",
       "         [ -1.03555174e+01,  -6.96556377e+00,   9.79166031e+00],\n",
       "         [ -1.33655300e+01,  -6.40230751e+00,   9.72085953e+00]],\n",
       "\n",
       "        [[ -5.48408737e+01,  -3.81320686e+01,  -2.92360859e+01],\n",
       "         [ -5.43678627e+01,  -4.27705269e+01,  -2.17258434e+01],\n",
       "         [ -6.01690407e+01,  -2.61104927e+01,  -2.92723885e+01],\n",
       "         ..., \n",
       "         [ -2.08203678e+01,  -1.45154285e+01,   2.71671772e+00],\n",
       "         [ -3.01684875e+01,  -3.56768727e+00,  -7.76742411e+00],\n",
       "         [ -2.46977730e+01,  -2.80330110e+00,  -2.69993600e-02]],\n",
       "\n",
       "        [[ -5.87749100e+01,  -3.01926365e+01,  -3.66005096e+01],\n",
       "         [ -4.41099548e+01,  -2.75546513e+01,  -2.02811832e+01],\n",
       "         [ -4.90691757e+01,  -3.80448418e+01,  -1.20217981e+01],\n",
       "         ..., \n",
       "         [ -2.35054760e+01,   1.22584485e-01,   2.06829961e-02],\n",
       "         [ -1.33538361e+01,  -1.23708134e+01,  -6.98069620e+00],\n",
       "         [ -1.93123436e+01,   2.02959418e+00,   4.00567961e+00]],\n",
       "\n",
       "        ..., \n",
       "        [[ -4.59157410e+01,  -4.82493057e+01,  -5.11277733e+01],\n",
       "         [ -4.46958084e+01,  -5.61829338e+01,  -5.40635681e+01],\n",
       "         [ -5.11738052e+01,  -5.84332886e+01,  -4.92429848e+01],\n",
       "         ..., \n",
       "         [ -5.27088051e+01,  -5.51560783e+01,  -4.63239822e+01],\n",
       "         [ -5.31908798e+01,  -5.95125389e+01,  -5.66012306e+01],\n",
       "         [ -5.15995979e+01,  -5.58317451e+01,  -5.88445435e+01]],\n",
       "\n",
       "        [[ -3.64954338e+01,  -4.35393791e+01,  -4.68927689e+01],\n",
       "         [  1.60333645e+00,  -2.44470921e+01,  -4.20017242e+01],\n",
       "         [ -9.64327908e+00,  -2.55828972e+01,  -4.70867233e+01],\n",
       "         ..., \n",
       "         [  9.45407963e+00,  -2.46570015e+01,  -5.51776848e+01],\n",
       "         [  9.24537563e+00,  -2.13277798e+01,  -4.69639244e+01],\n",
       "         [ -4.48635960e+00,  -2.40026569e+01,  -4.08776932e+01]],\n",
       "\n",
       "        [[ -1.61704254e+01,  -3.07208576e+01,  -4.44113693e+01],\n",
       "         [  4.30422058e+01,   1.04872198e+01,   4.62004042e+00],\n",
       "         [  3.71011124e+01,   1.05500345e+01,  -5.29782248e+00],\n",
       "         ..., \n",
       "         [  4.10921211e+01,   1.64066982e+01,  -8.22301197e+00],\n",
       "         [  4.34419746e+01,   1.34693546e+01,  -2.48676376e+01],\n",
       "         [  4.03979950e+01,   2.32419491e+01,  -2.53005810e+01]]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(model['input'].assign(input_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#500 iterations for testing\n",
    "ITERATIONS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "sum :  1.79307e+06\n",
      "cost:  1.87843e+11\n",
      "Iteration 10\n",
      "sum :  1.83378e+06\n",
      "cost:  3.69226e+10\n",
      "Iteration 20\n",
      "sum :  1.86438e+06\n",
      "cost:  1.40952e+10\n",
      "Iteration 30\n",
      "sum :  1.86048e+06\n",
      "cost:  6.68703e+09\n",
      "Iteration 40\n",
      "sum :  1.81871e+06\n",
      "cost:  4.42749e+09\n",
      "Iteration 50\n",
      "sum :  1.7645e+06\n",
      "cost:  3.27165e+09\n",
      "Iteration 60\n",
      "sum :  1.72238e+06\n",
      "cost:  2.62198e+09\n",
      "Iteration 70\n",
      "sum :  1.6907e+06\n",
      "cost:  2.20032e+09\n",
      "Iteration 80\n",
      "sum :  1.66452e+06\n",
      "cost:  1.90731e+09\n",
      "Iteration 90\n",
      "sum :  1.64205e+06\n",
      "cost:  1.68656e+09\n",
      "Iteration 100\n",
      "sum :  1.62142e+06\n",
      "cost:  1.51235e+09\n",
      "Iteration 110\n",
      "sum :  1.60196e+06\n",
      "cost:  1.37081e+09\n",
      "Iteration 120\n",
      "sum :  1.58345e+06\n",
      "cost:  1.25258e+09\n",
      "Iteration 130\n",
      "sum :  1.56573e+06\n",
      "cost:  1.15248e+09\n",
      "Iteration 140\n",
      "sum :  1.54835e+06\n",
      "cost:  1.0664e+09\n",
      "Iteration 150\n",
      "sum :  1.53117e+06\n",
      "cost:  9.91602e+08\n",
      "Iteration 160\n",
      "sum :  1.51416e+06\n",
      "cost:  9.2599e+08\n",
      "Iteration 170\n",
      "sum :  1.49719e+06\n",
      "cost:  8.67926e+08\n",
      "Iteration 180\n",
      "sum :  1.48002e+06\n",
      "cost:  8.16204e+08\n",
      "Iteration 190\n",
      "sum :  1.46248e+06\n",
      "cost:  7.69846e+08\n",
      "Iteration 200\n",
      "sum :  1.44466e+06\n",
      "cost:  7.28192e+08\n",
      "Iteration 210\n",
      "sum :  1.42658e+06\n",
      "cost:  6.9067e+08\n",
      "Iteration 220\n",
      "sum :  1.4081e+06\n",
      "cost:  6.56631e+08\n",
      "Iteration 230\n",
      "sum :  1.38918e+06\n",
      "cost:  6.25581e+08\n",
      "Iteration 240\n",
      "sum :  1.36994e+06\n",
      "cost:  5.97215e+08\n",
      "Iteration 250\n",
      "sum :  1.35043e+06\n",
      "cost:  5.71118e+08\n",
      "Iteration 260\n",
      "sum :  1.33068e+06\n",
      "cost:  5.47077e+08\n",
      "Iteration 270\n",
      "sum :  1.31066e+06\n",
      "cost:  5.2497e+08\n",
      "Iteration 280\n",
      "sum :  1.29031e+06\n",
      "cost:  5.04621e+08\n",
      "Iteration 290\n",
      "sum :  1.2697e+06\n",
      "cost:  4.858e+08\n",
      "Iteration 300\n",
      "sum :  1.24882e+06\n",
      "cost:  4.68255e+08\n",
      "Iteration 310\n",
      "sum :  1.22761e+06\n",
      "cost:  4.51887e+08\n",
      "Iteration 320\n",
      "sum :  1.20612e+06\n",
      "cost:  4.36544e+08\n",
      "Iteration 330\n",
      "sum :  1.18434e+06\n",
      "cost:  4.22122e+08\n",
      "Iteration 340\n",
      "sum :  1.16232e+06\n",
      "cost:  4.0853e+08\n",
      "Iteration 350\n",
      "sum :  1.14009e+06\n",
      "cost:  3.957e+08\n",
      "Iteration 360\n",
      "sum :  1.11761e+06\n",
      "cost:  3.83552e+08\n",
      "Iteration 370\n",
      "sum :  1.09492e+06\n",
      "cost:  3.72067e+08\n",
      "Iteration 380\n",
      "sum :  1.07198e+06\n",
      "cost:  3.61205e+08\n",
      "Iteration 390\n",
      "sum :  1.04882e+06\n",
      "cost:  3.50896e+08\n",
      "Iteration 400\n",
      "sum :  1.02547e+06\n",
      "cost:  3.4112e+08\n",
      "Iteration 410\n",
      "sum :  1.00199e+06\n",
      "cost:  3.31862e+08\n",
      "Iteration 420\n",
      "sum :  978359.0\n",
      "cost:  3.23079e+08\n",
      "Iteration 430\n",
      "sum :  954541.0\n",
      "cost:  3.14722e+08\n",
      "Iteration 440\n",
      "sum :  930540.0\n",
      "cost:  3.06736e+08\n",
      "Iteration 450\n",
      "sum :  906428.0\n",
      "cost:  2.99121e+08\n",
      "Iteration 460\n",
      "sum :  882131.0\n",
      "cost:  2.91827e+08\n",
      "Iteration 470\n",
      "sum :  857740.0\n",
      "cost:  2.8482e+08\n",
      "Iteration 480\n",
      "sum :  833214.0\n",
      "cost:  2.78114e+08\n",
      "Iteration 490\n",
      "sum :  808609.0\n",
      "cost:  2.71698e+08\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(model['input'].assign(input_image))\n",
    "for it in range(ITERATIONS):\n",
    "    sess.run(train_step)\n",
    "    \n",
    "    if it % 10 == 0:\n",
    "        output_image = sess.run(model['input'])\n",
    "        print('Iteration %d' % (it))\n",
    "        print('sum : ', sess.run(tf.reduce_sum(output_image)))\n",
    "        print('cost: ', sess.run(loss_total))\n",
    "        #if it%100 == 0:\n",
    "        #if not os.path.exists(OUTPUT_DIR):\n",
    "        #    os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "        filename = '/Users/til018/Desktop/style/output2/%d.png' % (it)\n",
    "        save_image(filename, output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
